\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{R\'esum\'e}
\section*{R\'ESUM\'E}

\`A l'\`ere du \textit{big data}, la qualité de toute décision dépend de la qualité des données utilisées. En effet, en l’absence de données fiables, une entreprise peut prendre potentiellement de mauvaises décisions. Notre \'etude vise dans un premier temps, \`a d\'etecter avec Apache Griffin les probl\`emes de qualit\'e sur les donn\'ees du projet socle de donn\'ees de la Digital Factory de Saham Maroc, puis \`a appliquer des correctifs lorsque cela est possible. De l'analyse th\'eorique effectu\'ee, nous avons retenu que la qualité des données, désigne l’aptitude de l’ensemble des caractéristiques intrinsèques des données (compl\'etude, cohérence, unicité, validit\'e, exactitude,actualit\'e) à satisfaire des exigences internes et des exigences externes à l’organisation. Pour pouvoir l'\'evaluer efficacement, nous avons eu recours \`a Apache Griffin. Il s'agit d'une plateforme \textit{big data}, qui offre des services de qualit\'e de donn\'ees. Elle permet d'\'editer des r\`egles de qualit\'e et de stocker les m\'etriques \`a des fins de visualisation ou d'historisation. L'\'evaluation de la qualit\'e des  extractions tables des 'Detail\_Victimes' et 'Inventaire\_Sinistre', a permis de relever plusieurs incoh\'erences que nous avons corrigées en utilisant PySpark, au moyen d'algorithmes de redressement.\\
\textbf{Mots cl\'es}: qualit\'e, donn\'ees, \textit{big data}, \'evaluation, correction, Griffin, anomalies
\section*{ABSTRACT}

In the age of big data, the quality of any decision depends on the quality of the data used. Indeed, without reliable data, a company can potentially make bad decisions. Our study aims, first, to detect with Apache Griffin the quality problems on the data of the Digital Factory of Saham Maroc, then to apply corrective measures when possible. From the theoretical analysis carried out, we have retained that data quality refers to the ability of all the intrinsic characteristics of the data (completeness, consistency, uniqueness, validity, accuracy, timeliness) to meet internal requirements and external requirements to the organization. To be able to evaluate it efficiently, we used Apache Griffin. It is a big data platform, which offers data quality services. It allows editing quality rules and store metrics for visualization or historical purposes. The quality assessment of the 'Detail\_Victime' and 'Inventaire\_Sinistre' extraction tables revealed several inconsistencies that we corrected using PySpark, by means of a rectification algorithm.\\
\textbf{Key words}: quality, data, big data, evaluation, correction, Griffin, inconsistencies